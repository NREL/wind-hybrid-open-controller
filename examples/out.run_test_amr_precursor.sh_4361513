Job name       = run_test_amr_precursor.sh
Num. nodes     = 8
Num. MPI Ranks = 736
Num. threads   = 
Working dir    = /home/ahenry/toolboxes/whoc_env/wind-hybrid-open-controller/examples
amr-wind executable = /home/ahenry/toolboxes/whoc_env/amr-wind/spack-build-bmx2pfy/amr_wind
==============================================================================
                AMR-Wind (https://github.com/exawind/amr-wind)

  AMR-Wind version :: 754dd54
  AMR-Wind Git SHA :: 754dd54e0dd4501be2b1c201fd84ba37628d801b
  AMReX version    :: 24.03-36-g748f8dfea597

  Exec. time       :: Thu Jun 20 07:20:54 2024
  Build time       :: Apr  9 2024 13:12:57
  C++ compiler     :: GNU 8.5.0

  MPI              :: ON    (Num. ranks = 736)
  GPU              :: OFF
  OpenMP           :: OFF

  Enabled third-party libraries: 
    NetCDF    4.7.4
    HYPRE     2.31.0
    OpenFAST  

           This software is released under the BSD 3-clause license.           
 See https://github.com/Exawind/amr-wind/blob/development/LICENSE for details. 
------------------------------------------------------------------------------

Initializing AMReX (24.03-36-g748f8dfea597)...
MPI initialized with 736 MPI processes
MPI initialized with thread support level 0
AMReX (24.03-36-g748f8dfea597) initialized
Initializing AMR-Wind ...
helics fedinitstring: --federates=1 --broker_address=127.0.0.1 --brokerport=23405
Initializing boundary conditions for velocity_mueff
Initializing boundary conditions for velocity
Initializing boundary conditions for density
Initializing boundary conditions for p
Initializing boundary conditions for velocity_src_term
Initializing boundary conditions for gp
Creating PDESystem instance: ICNS-Godunov
ABLWallFunction: log_law_height not specified for ABL physics. Assuming log_law_height = first cell height
Initializing boundary conditions for temperature_mueff
Initializing boundary conditions for temperature
Initializing boundary conditions for temperature_src_term
Creating PDESystem instance: Temperature-Godunov
Creating ABLStatsBase instance: precursor
Creating Physics instance: ABL
Initializing boundary conditions for mu_turb
using default CellConsLinear interpolation for TKE fillpatch
Initializing boundary conditions for tke_mueff
Initializing boundary conditions for tke
Initializing boundary conditions for tke_src_term
Creating PDESystem instance: TKE-Godunov
Creating TurbulenceModel instance: OneEqKsgsM84-ConstTransport
Creating PostProcessBase instance: Sampling
Creating PostProcessBase instance: Sampling
Initializing I/O manager
Creating mesh... done
Grid summary: 
  Level 0   1024 grids  33554432 cells  100 % of domain
            smallest grid: 32 x 32 x 32  biggest grid: 32 x 32 x 32

Shear Stress model: moeng
Heat Flux model: moeng
Creating MomentumSource instance: BoussinesqBuoyancy
Creating MomentumSource instance: CoriolisForcing
Creating MomentumSource instance: ABLForcing
Creating TKESource instance: KsgsM84Src
Creating SamplerBase instance: PlaneSampler
Creating SamplerBase instance: LineSampler
Begin initial projection
  Nodal_projection               0       4.441078446e-17       4.441078446e-17
Completed initial projection

Begin initial pressure iterations. Num. iters = 3
dt: 0.5
CFL: 0.395927 (conv: 0.395927 diff: 0 src: 0 )

Godunov:
  System                     Iters      Initial residual        Final residual
  ----------------------------------------------------------------------------
Abort(945466511) on node 524 (rank 524 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=14, array_of_requests=0x3513ee0, array_of_statuses=0x322ea90) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(945466511) on node 524 (rank 524 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=14, array_of_requests=0x3513ee0, array_of_statuses=0x322ea90) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(408595599) on node 549 (rank 549 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=14, array_of_requests=0x389f180, array_of_statuses=0x3878610) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(408595599) on node 549 (rank 549 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=14, array_of_requests=0x389f180, array_of_statuses=0x3878610) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
srun: error: x1003c4s0b1n1: tasks 524,549: Segmentation fault (core dumped)
Abort(475704463) on node 152 (rank 152 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=32, array_of_requests=0x4d4d2e0, array_of_statuses=0x1044050) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(140160143) on node 177 (rank 177 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=30, array_of_requests=0x501b500, array_of_statuses=0x18c4230) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(341486735) on node 182 (rank 182 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=24, array_of_requests=0x4cf5c90, array_of_statuses=0xfc09b0) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(341486735) on node 182 (rank 182 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=24, array_of_requests=0x4cf5c90, array_of_statuses=0xfc09b0) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(140160143) on node 161 (rank 161 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=20, array_of_requests=0x5686d40, array_of_statuses=0x4a33070) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(140160143) on node 161 (rank 161 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=20, array_of_requests=0x5686d40, array_of_statuses=0x4a33070) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(5942415) on node 183 (rank 183 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=37, array_of_requests=0x6573760, array_of_statuses=0x5a8c2d0) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(5942415) on node 183 (rank 183 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=37, array_of_requests=0x6573760, array_of_statuses=0x5a8c2d0) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(140160143) on node 177 (rank 177 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=30, array_of_requests=0x501b500, array_of_statuses=0x18c4230) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
Abort(475704463) on node 152 (rank 152 in comm 0): Fatal error in internal_Waitall: Other MPI error, error stack:
internal_Waitall(82)..........: MPI_Waitall(count=32, array_of_requests=0x4d4d2e0, array_of_statuses=0x1044050) failed
MPIR_Waitall(1099)............: 
MPIR_Waitall_state(976).......: 
MPID_Progress_wait(335).......: 
MPIDI_progress_test(158)......: 
MPIDI_OFI_handle_cq_error(627): OFI poll failed (ofi_events.c:627:MPIDI_OFI_handle_cq_error:Input/output error)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 4361513.0 ON x1003c3s2b0n1 CANCELLED AT 2024-06-20T07:36:47 ***
srun: error: x1003c3s4b1n0: tasks 184-194,196-275: Killed
srun: error: x1003c4s0b1n1: tasks 460-523,525-548,550-551: Killed
srun: error: x1003c4s1b0n1: tasks 644-735: Killed
srun: error: x1003c3s2b0n1: tasks 0-91: Killed
srun: error: x1003c3s3b0n0: tasks 152,161,177,182-183: Segmentation fault (core dumped)
srun: error: x1003c3s5b1n0: tasks 276-367: Killed
srun: error: x1003c3s6b0n1: tasks 368-459: Killed
srun: error: x1003c3s3b0n0: tasks 92-151,153-160,162-176,178-181: Killed
srun: error: x1003c3s4b1n0: task 195: Killed
srun: error: Node failure on x1003c4s1b0n0
slurmstepd: error: *** JOB 4361513 ON x1003c3s2b0n1 CANCELLED AT 2024-06-20T07:37:02 DUE TO NODE FAILURE, SEE SLURMCTLD LOG FOR DETAILS ***
